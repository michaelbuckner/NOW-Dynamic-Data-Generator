/**
 * OpenRouterLLMIntegration.js
 * 
 * Implementation of LLM integration with OpenRouter for the Bulk Data Generator.
 * This file provides a faster alternative to local Ollama by using cloud-based LLMs.
 * 
 * To use this integration:
 * 1. Get an API key from https://openrouter.ai/
 * 2. Set your API key as an environment variable: OPENROUTER_API_KEY
 *    or pass it as an option when creating the OpenRouterLLM instance
 */

const https = require('https');

class OpenRouterLLM {
  constructor(options = {}) {
    this.apiKey = options.apiKey || process.env.OPENROUTER_API_KEY;
    if (!this.apiKey) {
      console.warn('Warning: No OpenRouter API key provided. Set OPENROUTER_API_KEY environment variable or pass apiKey in options.');
    }
    
    this.model = options.model || 'google/gemini-2.0-flash-001';
    this.temperature = options.temperature || 0.7;
    this.maxTokens = options.maxTokens || 100;
    
    console.log(`OpenRouter LLM integration initialized with model: ${this.model}`);
  }

  /**
   * Generate text using OpenRouter
   * @param {string} prompt - The prompt to generate text from
   * @param {number} maxLength - Maximum length of the generated text
   * @returns {Promise<string>} - The generated text
   */
  async generateText(prompt, maxLength = 100) {
    try {
      if (!this.apiKey) {
        throw new Error('OpenRouter API key is required. Set OPENROUTER_API_KEY environment variable or pass apiKey in options.');
      }
      
      const response = await this._callOpenRouterAPI(prompt, Math.min(maxLength, this.maxTokens));
      return response.substring(0, maxLength);
    } catch (error) {
      console.error('Error generating text with OpenRouter:', error.message);
      // Fallback to a simple text generation if OpenRouter fails
      return `Generated text for: ${prompt}`.substring(0, maxLength);
    }
  }

  /**
   * Call the OpenRouter API
   * @param {string} prompt - The prompt to generate text from
   * @param {number} maxTokens - Maximum number of tokens to generate
   * @returns {Promise<string>} - The generated text
   */
  _callOpenRouterAPI(prompt, maxTokens) {
    return new Promise((resolve, reject) => {
      const data = JSON.stringify({
        model: this.model,
        messages: [
          { role: "user", content: prompt }
        ],
        temperature: this.temperature,
        max_tokens: maxTokens
      });

      const options = {
        hostname: 'openrouter.ai',
        port: 443,
        path: '/api/v1/chat/completions',
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Content-Length': data.length,
          'Authorization': `Bearer ${this.apiKey}`,
          'HTTP-Referer': 'https://github.com/NOW-Dynamic-Data-Generator', // Replace with your actual site
          'X-Title': 'NOW-Dynamic-Data-Generator'
        }
      };

      const req = https.request(options, (res) => {
        let responseData = '';

        res.on('data', (chunk) => {
          responseData += chunk;
        });

        res.on('end', () => {
          try {
            const parsedResponse = JSON.parse(responseData);
            
            if (parsedResponse.error) {
              reject(new Error(`OpenRouter API error: ${parsedResponse.error.message || JSON.stringify(parsedResponse.error)}`));
              return;
            }
            
            if (parsedResponse.choices && parsedResponse.choices.length > 0) {
              const generatedText = parsedResponse.choices[0].message.content.trim();
              
              // Clean up the response - remove any markdown code block markers
              const cleanedText = generatedText
                .replace(/```json\s*/g, '')
                .replace(/```\s*$/g, '');
              
              resolve(cleanedText);
            } else {
              reject(new Error('No text was generated by OpenRouter'));
            }
          } catch (error) {
            reject(new Error(`Failed to parse OpenRouter response: ${error.message}`));
          }
        });
      });

      req.on('error', (error) => {
        reject(new Error(`OpenRouter API request failed: ${error.message}`));
      });

      req.write(data);
      req.end();
    });
  }
}

// Example usage:
async function testOpenRouterLLM() {
  const llm = new OpenRouterLLM({
    model: 'google/gemini-2.0-flash-001', // OpenRouter model identifier
    temperature: 0.7,
    maxTokens: 100
  });

  const prompt = 'Generate a short description for a network incident';
  console.log(`Prompt: ${prompt}`);
  
  const result = await llm.generateText(prompt, 100);
  console.log(`Generated text: ${result}`);
}

// Uncomment to test:
// testOpenRouterLLM().catch(console.error);

module.exports = OpenRouterLLM;
